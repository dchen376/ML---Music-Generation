# FSDD
The sound dataset was gathered from this git repository -> Free Spoken Digit Dataset (FSDD):
https://github.com/Jakobovski/free-spoken-digit-dataset

# MNIST
The analysis.py is using MNIST (Modified National Institute of Standards and Tehchnology) as a dataset for pre-analysis purpose; dataset of handwritten digits.

# Youtube reference
Youtube tutorials on music generation:
https://youtube.com/playlist?list=PL-wATfeyAMNpEyENTc-tVH5tfLGKtSWPp&si=53DtJN6I_OKJFAr-



# Steps in the project
step 0 - to understand vanilla autoencoder which consists of both an encoder and a decoder.
  - build an encoder
  - build a decoder
  - combine and make the autoencoder
  - train the autoencoder
  - test the autoencoder with mnist dataset
  - plot the testing results
